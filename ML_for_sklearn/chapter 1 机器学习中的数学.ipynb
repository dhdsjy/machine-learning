{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义\n",
    "对于给定任务T，在合理性能度量方案P的前提下，某计算程序可以自主学习任务T的经验E；随着提供合适、优质、大量的经验E，该程序对于任务T的性能逐步提高\n",
    "## 算法一览\n",
    "### Unsupervised\n",
    "#### Continuous\n",
    "+ clutering&Dimensionality\n",
    "+ Reduction\n",
    "  + SVD\n",
    "  + PCA\n",
    "  + k-means\n",
    " \n",
    "#### Categorical\n",
    "+ Association analysis\n",
    "  + Apriori\n",
    "  + FP-Growth\n",
    "+ Hidden Markov Model\n",
    "\n",
    "### Supervised\n",
    "#### Continuous\n",
    "+ Regreesion\n",
    "  + Linear\n",
    "  + Polynomial\n",
    "+ Decision Trees\n",
    "+ Random Forests\n",
    "\n",
    "#### Categorical\n",
    "+ Classification\n",
    "  + KNN\n",
    "  + Trees\n",
    "  + LR\n",
    "  + Naive Bayes\n",
    "  + SVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高数回顾\n",
    "### 导数\n",
    "### 凸函数\n",
    "\n",
    "## 概率与统计\n",
    "+ 统计问题是概率问题的逆向工程\n",
    "  + 概率：已知总体，求部分的概率\n",
    "  + 统计：已知部分，估计总体\n",
    "+ 特征工程的一个目的：将耦合的特征拆成独立或线性相关的特征\n",
    "+ 独立 P(AB)=P(A)P(B)\n",
    "+ 不相关 cov(A,B) = 0 说明AB之间没有线性关系，但可能存在其他函数关系，不能保证AB相互独立\n",
    "+ 协方差是两个随机变量具有相同方向变化趋势的度量，协方差上界 |cov(x,y)|<=a1a2\n",
    "+ 皮尔逊相关系数$p_{xy}=\\frac{cov(x,y)}{\\sqrt{var(x)var(y)}}$\n",
    "+ 协方差矩阵 协方差矩阵是对称阵\n",
    "+ 变异系数 比较两组数据离散程度大小的时候，如果两组数据的测量尺度相差太大，或者数据量纲的不同，直接使用标准差来进行比较不合适，此时就应当消除测量尺度和量纲的影响，而变异系数可以做到这一点，他是标准差与其平均数的比。CV虽然没有量纲，同时又按照其均数大小进行了标准化，这样就可以进行客观比较了。因此，可以认为变异系数和极差、标准差和方差一样，都是反映数据离散程度的绝对值。其数据大小不仅受变量值离散程度的影响，而且还受变量值平均水平大小的影响。\n",
    "+ 偏度\n",
    "+ 峰度\n",
    "\n",
    "### 重要定理与不等式\n",
    "#### 杰森不等式\n",
    "\n",
    "$$f(\\theta{x}+(1-\\theta)y)<=\\theta{f(x)+(1-\\theta)f(y)}$$\n",
    "$$f(Ex)<=Ef(x)$$\n",
    "\n",
    "#### 切比雪夫不等式\n",
    "$$P\\{|X-u|>=e\\}<=\\frac{a^2}{e^2}$$\n",
    "切比雪夫角度理解方差：X的方差越小，时间$\\{|X-u|>=e\\}$发生的概率越大，即X取值基本集中在期望u附近\n",
    "\n",
    "#### 大数定理\n",
    "#### 中心极限定理\n",
    "实际问题中，很多随机现象可以看做许多的独立影响的综合反应，往往近似服从正态分布\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 凸优化初步\n",
    "+ hessian矩阵　对称矩阵（必定是方阵），对角元求两次偏导，非对角元不是\n",
    "+ （标量情况）严格局部最小值点　$f^{''}(x)>0$ ，二阶导等于０即为鞍点\n",
    "+ (矢量情况)　$\\nabla{^2}f(x)\\succ{0}$（正定）严格局部极小点；正定　负定是通过特征值判断的\n",
    "\n",
    "无约束优化直接分析的局限性\n",
    "+ 有可能函数不可导\n",
    "+ 即使可导，也不一定能求出值（高度非线性）\n",
    "+ 即使求出来，也可能是一个集合\n",
    "\n",
    "\n",
    "**无约束优化迭代法**\n",
    "1. 选定一个初始点，设置一个阈值，计数k=0\n",
    "2. 决定搜索方向$d_k$,使得函数下降\n",
    "3. 决定步长$a_k$,使得$f()$\n",
    "\n",
    "KKT条件（如何把约束优化转化为非约束优化）\n",
    "\n",
    "### 凸函数\n",
    "KKT条件变成充要条件，局部最小变成全局最小\n",
    "\n",
    "感觉自己理论弱，但又看不下去，理解不了　心浮气躁　还是偏应用吧。。。。\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
