{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "You have to supply one of 'by' and 'level'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-24300c82e617>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#print glass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mglass\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mglass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze)\u001b[0m\n\u001b[0;32m   3431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3432\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mby\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3433\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You have to supply one of 'by' and 'level'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3434\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3435\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n",
      "\u001b[1;31mTypeError\u001b[0m: You have to supply one of 'by' and 'level'"
     ]
    }
   ],
   "source": [
    "# 多类别分类数据处理\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-\"\n",
    "              \"learning-databases/glass/glass.data\")\n",
    "#print target_url\n",
    "\n",
    "glass = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "#print glass\n",
    "glass.columns = ['Id', 'RI', 'Na', 'Mg', 'Al', 'Si',\n",
    "                 'K', 'Ca', 'Ba', 'Fe', 'Type']\n",
    "\n",
    "#print glass\n",
    "# print glass['Type'].groupby(axis=1).count() 分类统计都忘记了。。。\n",
    "glass.info()\n",
    "\n",
    "#generate statistical summaries\n",
    "summary = glass.describe()\n",
    "print(summary)\n",
    "ncol1 = len(glass.columns)\n",
    "print ncol1\n",
    "\n",
    "glassNormalized = glass.iloc[:, 1:ncol1]\n",
    "print glassNormalized.head()\n",
    "ncol2 = len(glassNormalized.columns)\n",
    "summary2 = glassNormalized.describe()\n",
    "\n",
    "for i in range(ncol2):\n",
    "    mean = summary2.iloc[1, i]\n",
    "    sd = summary2.iloc[2, i]\n",
    "    glassNormalized.iloc[:,i:(i + 1)] = \\\n",
    "        (glassNormalized.iloc[:,i:(i + 1)] - mean) / sd\n",
    "\n",
    "array = glassNormalized.values\n",
    "boxplot(array)\n",
    "plot.xlabel(\"Attribute Index\")\n",
    "plot.ylabel((\"Quartile Ranges - Normalized \"))\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程\n",
    "特征工程一般需要通过一个由人工参与的、迭代的过程来完成特征选择，决定*可能最优的特征*，并且尝试不同的特征组合。\n",
    "\n",
    "## 模型性能评估\n",
    "\n",
    "### 回归问题\n",
    "+ 均方误差（Mean Square error）\n",
    "$$MSE=(\\frac{1}{m})\\sum_{i=1}^m(y_i-pred(x_i))^2$$\n",
    "$$RMSE=\\sqrt{MSE}$$\n",
    "+ 平均绝对误差（Mean absolute error）\n",
    "$$MAE=(\\frac{1}{m})\\sum_{i=1}^m|y_i-pred(x_i)|$$\n",
    "\n",
    "\n",
    "\n",
    "### 分类问题\n",
    "\n",
    "## 影响算法选择及性能的因素\n",
    "### 模型复杂度\n",
    "如果问题很复杂，一个拥有大量数据的复杂模型可以很精确的生成结果。然而，如果真实模型不复杂或者没有足够多的数据，一个线性模型可能是最好的答案。暂且可初步得出这样一个结论：对于列比行多的数据集或相对简单的问题，倾向于使用线性模型，反之，使用非线性模型\n",
    "\n",
    "### 数据量\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of xTrain array', (138L, 60L))\n",
      "('Shape of yTrain array', (138L,))\n",
      "('Shape of xTest array', (70L, 60L))\n",
      "('Shape of yTest array', (70L,))\n",
      "('Some values predicted by model', array([-0.10240253,  0.42090698,  0.38593034,  0.36094537,  0.31520494]), array([ 1.11094176,  1.12242751,  0.77626699,  1.02016858,  0.66338081]))\n",
      "tp = 68.0\tfn = 6.0\n",
      "fp = 7.0\ttn = 57.0\n",
      "\n",
      "tp = 28.0\tfn = 9.0\n",
      "fp = 9.0\ttn = 24.0\n",
      "\n",
      "[ 0.        0.        0.015625  0.015625  0.046875  0.046875  0.078125\n",
      "  0.078125  0.09375   0.09375   0.140625  0.140625  0.171875  0.171875\n",
      "  0.1875    0.1875    0.203125  0.203125  0.21875   0.21875   1.      ]\n",
      "[ 0.01351351  0.78378378  0.78378378  0.83783784  0.83783784  0.89189189\n",
      "  0.89189189  0.90540541  0.90540541  0.91891892  0.91891892  0.93243243\n",
      "  0.93243243  0.95945946  0.95945946  0.97297297  0.97297297  0.98648649\n",
      "  0.98648649  1.          1.        ]\n",
      "[ 1.4146433   0.64195949  0.63982219  0.61712091  0.60364498  0.56456686\n",
      "  0.54019672  0.52149739  0.51821399  0.51175085  0.4787469   0.47771642\n",
      "  0.45719099  0.4289069   0.42090698  0.40362921  0.38593034  0.36383074\n",
      "  0.36094537  0.34698015 -0.39210439]\n",
      "AUC for in-sample ROC curve: 0.979519\n"
     ]
    }
   ],
   "source": [
    "## 分类器性能\n",
    "#use scikit learn package to perform linear regression\n",
    "#read in the rocks versus mines data set from uci.edu data repository\n",
    "import urllib2\n",
    "import numpy\n",
    "import random\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pylab as pl\n",
    "\n",
    "\n",
    "def confusionMatrix(predicted, actual, threshold):\n",
    "    if len(predicted) != len(actual): return -1\n",
    "    tp = 0.0\n",
    "    fp = 0.0\n",
    "    tn = 0.0\n",
    "    fn = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] > 0.5: #labels that are 1.0  (positive examples)\n",
    "            if predicted[i] > threshold:\n",
    "                tp += 1.0 #correctly predicted positive\n",
    "            else:\n",
    "                fn += 1.0 #incorrectly predicted negative\n",
    "        else:              #labels that are 0.0 (negative examples)\n",
    "            if predicted[i] < threshold:\n",
    "                tn += 1.0 #correctly predicted negative\n",
    "            else:\n",
    "                fp += 1.0 #incorrectly predicted positive\n",
    "    rtn = [tp, fn, fp, tn]\n",
    "    return rtn\n",
    "\n",
    "\n",
    "#read data from uci data repository\n",
    "target_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\"\n",
    "data = urllib2.urlopen(target_url)\n",
    "#print data.head()\n",
    "\n",
    "#arrange data into list for labels and list of lists for attributes\n",
    "xList = []\n",
    "labels = []\n",
    "for line in data:\n",
    "    #split on comma\n",
    "    row = line.strip().split(\",\")\n",
    "    #assign label 1.0 for \"M\" and 0.0 for \"R\"\n",
    "    if(row[-1] == 'M'):\n",
    "        labels.append(1.0)\n",
    "    else:\n",
    "        labels.append(0.0)\n",
    "    #remove label from row\n",
    "    row.pop()\n",
    "    #convert row to floats\n",
    "    floatRow = [float(num) for num in row]\n",
    "    xList.append(floatRow)\n",
    "# print xList\n",
    "# print labels\n",
    "#divide attribute matrix and label vector into training(2/3 of data) and test sets (1/3 of data)\n",
    "indices = range(len(xList))\n",
    "xListTest = [xList[i] for i in indices if i%3 == 0 ]\n",
    "xListTrain = [xList[i] for i in indices if i%3 != 0 ]\n",
    "labelsTest = [labels[i] for i in indices if i%3 == 0]\n",
    "labelsTrain = [labels[i] for i in indices if i%3 != 0]\n",
    "\n",
    "#form list of list input into numpy arrays to match input class for scikit-learn linear model\n",
    "xTrain = numpy.array(xListTrain);\n",
    "yTrain = numpy.array(labelsTrain); \n",
    "xTest = numpy.array(xListTest);\n",
    "yTest = numpy.array(labelsTest)\n",
    "\n",
    "#check shapes to see what they look like\n",
    "print(\"Shape of xTrain array\", xTrain.shape)\n",
    "print(\"Shape of yTrain array\", yTrain.shape)\n",
    "print(\"Shape of xTest array\", xTest.shape)\n",
    "print(\"Shape of yTest array\", yTest.shape)\n",
    "\n",
    "#train linear regression model\n",
    "rocksVMinesModel = linear_model.LinearRegression()\n",
    "rocksVMinesModel.fit(xTrain,yTrain)\n",
    "\n",
    "#generate predictions on in-sample error\n",
    "trainingPredictions = rocksVMinesModel.predict(xTrain)\n",
    "print(\"Some values predicted by model\", trainingPredictions[0:5], trainingPredictions[-6:-1])\n",
    "\n",
    "#generate confusion matrix for predictions on training set (in-sample\n",
    "confusionMatTrain = confusionMatrix(trainingPredictions, yTrain, 0.5)\n",
    "#pick threshold value and generate confusion matrix entries\n",
    "tp = confusionMatTrain[0];\n",
    "fn = confusionMatTrain[1]; \n",
    "fp = confusionMatTrain[2];\n",
    "tn = confusionMatTrain[3]\n",
    "\n",
    "print(\"tp = \" + str(tp) + \"\\tfn = \" + str(fn) + \"\\n\" + \"fp = \" + str(fp) + \"\\ttn = \" + str(tn) + '\\n')\n",
    "\n",
    "#generate predictions on out-of-sample data\n",
    "testPredictions = rocksVMinesModel.predict(xTest)\n",
    "\n",
    "#generate confusion matrix from predictions on out-of-sample data\n",
    "conMatTest = confusionMatrix(testPredictions, yTest, 0.5)\n",
    "#pick threshold value and generate confusion matrix entries\n",
    "tp = conMatTest[0]; \n",
    "fn = conMatTest[1]; \n",
    "fp = conMatTest[2]; \n",
    "tn = conMatTest[3]\n",
    "print(\"tp = \" + str(tp) + \"\\tfn = \" + str(fn) + \"\\n\" + \"fp = \" + str(fp) + \"\\ttn = \" + str(tn) + '\\n')\n",
    "\n",
    "#generate ROC curve for in-sample\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(yTrain,trainingPredictions)\n",
    "print 'the fbr is',fpr\n",
    "print '',tpr\n",
    "print thresholds\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print( 'AUC for in-sample ROC curve: %f' % roc_auc)\n",
    "\n",
    "# Plot ROC curve\n",
    "pl.clf()\n",
    "pl.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "pl.plot([0, 1], [0, 1], 'k--')\n",
    "pl.xlim([0.0, 1.0])\n",
    "pl.ylim([0.0, 1.0])\n",
    "pl.xlabel('False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('In sample ROC rocks versus mines')\n",
    "pl.legend(loc=\"lower right\")\n",
    "pl.show()\n",
    "\n",
    "#generate ROC curve for out-of-sample\n",
    "fpr, tpr, thresholds = roc_curve(yTest,testPredictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print( 'AUC for out-of-sample ROC curve: %f' % roc_auc)\n",
    "\n",
    "# Plot ROC curve\n",
    "pl.clf()\n",
    "pl.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "pl.plot([0, 1], [0, 1], 'k--')\n",
    "pl.xlim([0.0, 1.0])\n",
    "pl.ylim([0.0, 1.0])\n",
    "pl.xlabel('False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('Out-of-sample ROC rocks versus mines')\n",
    "pl.legend(loc=\"lower right\")\n",
    "pl.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
