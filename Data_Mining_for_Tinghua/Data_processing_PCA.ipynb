{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[理解PCA SVD](http://fuzihao.org/blog/2015/12/04/理解PCA和SVD/)\n",
    "[PCA算法详解](http://blog.codinglabs.org/articles/pca-tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "（Principal Component Analysis，主成分分析）是一种常用的数据分析方法。PCA通过线性变换将原始数据变换为一组各维度线性无关的表示，可用于提取数据的主要特征分量，常用于高维数据的降维。PCA的过程就是通过某种线性变换，将样本矩阵（一般列（即属性）之间具有相关性）变换为一个新矩阵，让新矩阵的每一列不相关。\n",
    "\n",
    "### 一些基础知识\n",
    "**向量** n维向量可以等价表示为n维空间中的一条从原点发射的有向线段\n",
    "**内积与投影** \n",
    "<img src=http://img.blog.csdn.net/20150719221221291?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center>\n",
    "设向量B的模为1，则A与B的内积值等于A向B所在直线投影的矢量长度！\n",
    "\n",
    "**基** 要准确描述向量，首先要确定一组基，然后给出在基所在的各个直线上的投影值，就可以了\n",
    "在一个新基上，其坐标怎么表示？ 使用原来的坐标值在新基上投影即可，但是一般将基向量的模化为1\n",
    "<img src=http://img.blog.csdn.net/20150719222119999?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center>\n",
    "\n",
    "**基变换的矩阵表示**\n",
    "<img src=http://img.blog.csdn.net/20150719222220679?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center>\n",
    "矩阵左边两行表示表示两个基，乘以原向量，其结果即为新基的坐标\n",
    "\n",
    "**矩阵相乘的物理意义**\n",
    "\\begin{equation}\n",
    "\\left(\n",
    "\\begin{array}{lll}\n",
    "P_1\\\\\n",
    "P_2\\\\\n",
    "\\vdots\\\\\n",
    "P_R\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\left(\n",
    "\\begin{array}{ccc}\n",
    "a_1&a_2& \\cdots&a_M\n",
    "\\end{array}\n",
    "\\right)=\n",
    "\\left(\n",
    "\\begin{array}{rrr}\n",
    "P_1a_1&P_1a_2& \\cdots&P_1a_M\\\\\n",
    "P_2a_1&P_2a_2& \\cdots&P_2a_M\\\\\n",
    "\\vdots&\\vdots& \\ddots&\\vdots\\\\\n",
    "P_Ra_1&P_Ra_2& \\cdots&P_Ra_M\\\\\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\end{equation}\n",
    "\n",
    "左边是R*M 中间是N*M 右边是 R*M \n",
    "一般的，如果我们有M个N维向量，想将其变换为由R个N维向量表示的新空间中，那么首先将R个基按行组成矩阵A，然后将向量按列组成矩阵B，那么两矩阵的乘积AB就是变换结果，其中AB的第m列为A中第m列变换后的结果\n",
    "\n",
    "其中$P_i$是一个行向量，表示第i个基，$a_j$是一个列向量，表示第j个原始数据记录\n",
    "\n",
    "上述分析同时给矩阵相乘找到了一种物理解释：两个矩阵相乘的意义是将右边矩阵中的每一列列向量变换到左边矩阵中每一行行向量为基所表示的空间中去。更抽象的说，一个矩阵可以表示一种线性变换 即一个矩阵在另外一组基下的坐标\n",
    "\n",
    "**降维优化的目标**将一组N维向量降为K维（K大于0，小于N），其目标是选择K个单位（模为1）正交基，使得原始数据变换到这组基上后，各字段两两间协方差为0，而字段的方差则尽可能大（在正交的约束下，取最大的K个方差）。\n",
    "\n",
    "**协方差矩阵**\n",
    "<img src=http://img.blog.csdn.net/20150719222631031?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center>\n",
    "\n",
    "<img src=http://img.blog.csdn.net/20150719222702259?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center>\n",
    "\n",
    "<img src=http://img.blog.csdn.net/20150719222857201?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center>\n",
    "奇迹出现了！这个矩阵对角线上的两个元素分别是两个字段的方差，而其它元素是a和b的协方差。两者被统一到了一个矩阵的\n",
    "\n",
    "设我们有m个n维数据记录，将其按列排成n乘m的矩阵X，设C=1mXXTC=1mXXT，则C是一个对称矩阵，其对角线分别个各个字段的方差，而第i行j列和j行i列元素相同，表示i和j两个字段的协方差。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
